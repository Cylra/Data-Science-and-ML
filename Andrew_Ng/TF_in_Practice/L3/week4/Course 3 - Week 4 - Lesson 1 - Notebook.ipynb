{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zX4Kg8DUTKWO"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BOwsuGQQY9OL"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PRnDnCW-Z7qv",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n",
      "263\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "data=\"In the town of Athy one Jeremy Lanigan \\n Battered away til he hadnt a pound. \\nHis father died and made him a man again \\n Left him a farm and ten acres of ground. \\nHe gave a grand party for friends and relations \\nWho didnt forget him when come to the wall, \\nAnd if youll but listen Ill make your eyes glisten \\nOf the rows and the ructions of Lanigans Ball. \\nMyself to be sure got free invitation, \\nFor all the nice girls and boys I might ask, \\nAnd just in a minute both friends and relations \\nWere dancing round merry as bees round a cask. \\nJudy ODaly, that nice little milliner, \\nShe tipped me a wink for to give her a call, \\nAnd I soon arrived with Peggy McGilligan \\nJust in time for Lanigans Ball. \\nThere were lashings of punch and wine for the ladies, \\nPotatoes and cakes; there was bacon and tea, \\nThere were the Nolans, Dolans, OGradys \\nCourting the girls and dancing away. \\nSongs they went round as plenty as water, \\nThe harp that once sounded in Taras old hall,\\nSweet Nelly Gray and The Rat Catchers Daughter,\\nAll singing together at Lanigans Ball. \\nThey were doing all kinds of nonsensical polkas \\nAll round the room in a whirligig. \\nJulia and I, we banished their nonsense \\nAnd tipped them the twist of a reel and a jig. \\nAch mavrone, how the girls got all mad at me \\nDanced til youd think the ceiling would fall. \\nFor I spent three weeks at Brooks Academy \\nLearning new steps for Lanigans Ball. \\nThree long weeks I spent up in Dublin, \\nThree long weeks to learn nothing at all,\\n Three long weeks I spent up in Dublin, \\nLearning new steps for Lanigans Ball. \\nShe stepped out and I stepped in again, \\nI stepped out and she stepped in again, \\nShe stepped out and I stepped in again, \\nLearning new steps for Lanigans Ball. \\nBoys were all merry and the girls they were hearty \\nAnd danced all around in couples and groups, \\nTil an accident happened, young Terrance McCarthy \\nPut his right leg through miss Finnertys hoops. \\nPoor creature fainted and cried Meelia murther, \\nCalled for her brothers and gathered them all. \\nCarmody swore that hed go no further \\nTil he had satisfaction at Lanigans Ball. \\nIn the midst of the row miss Kerrigan fainted, \\nHer cheeks at the same time as red as a rose. \\nSome of the lads declared she was painted, \\nShe took a small drop too much, I suppose. \\nHer sweetheart, Ned Morgan, so powerful and able, \\nWhen he saw his fair colleen stretched out by the wall, \\nTore the left leg from under the table \\nAnd smashed all the Chaneys at Lanigans Ball. \\nBoys, oh boys, twas then there were runctions. \\nMyself got a lick from big Phelim McHugh. \\nI soon replied to his introduction \\nAnd kicked up a terrible hullabaloo. \\nOld Casey, the piper, was near being strangled. \\nThey squeezed up his pipes, bellows, chanters and all. \\nThe girls, in their ribbons, they got all entangled \\nAnd that put an end to Lanigans Ball.\"\n",
    "\n",
    "corpus = data.lower().split(\"\\n\")\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(tokenizer.word_index)\n",
    "print(total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "soPGVheskaQP"
   },
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# create predictors and label\n",
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJtwVB2NbOAP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n",
      "66\n",
      "8\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index['in'])\n",
    "print(tokenizer.word_index['the'])\n",
    "print(tokenizer.word_index['town'])\n",
    "print(tokenizer.word_index['of'])\n",
    "print(tokenizer.word_index['athy'])\n",
    "print(tokenizer.word_index['one'])\n",
    "print(tokenizer.word_index['jeremy'])\n",
    "print(tokenizer.word_index['lanigan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "49Cv68JOakwv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  4  2 66  8 67 68 69]\n"
     ]
    }
   ],
   "source": [
    "print(xs[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iY-jwvfgbEF8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(ys[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wtzlUMYadhKt",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  4  2 66  8 67 68]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(xs[5])\n",
    "print(ys[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H4myRpB1c4Gg",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w9vH8Y59ajYL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 10, 64)            16832     \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 40)                13600     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 263)               10783     \n",
      "=================================================================\n",
      "Total params: 41,215\n",
      "Trainable params: 41,215\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1)) #这个减1很关键\n",
    "model.add(Bidirectional(LSTM(20)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples\n",
      "Epoch 1/500\n",
      "453/453 [==============================] - 2s 4ms/sample - loss: 5.5672 - accuracy: 0.0287\n",
      "Epoch 2/500\n",
      "453/453 [==============================] - 0s 197us/sample - loss: 5.5394 - accuracy: 0.0640\n",
      "Epoch 3/500\n",
      "453/453 [==============================] - 0s 176us/sample - loss: 5.4827 - accuracy: 0.0618\n",
      "Epoch 4/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 5.3147 - accuracy: 0.0530\n",
      "Epoch 5/500\n",
      "453/453 [==============================] - 0s 178us/sample - loss: 5.1409 - accuracy: 0.0508\n",
      "Epoch 6/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 5.0699 - accuracy: 0.0508\n",
      "Epoch 7/500\n",
      "453/453 [==============================] - 0s 178us/sample - loss: 5.0304 - accuracy: 0.0508\n",
      "Epoch 8/500\n",
      "453/453 [==============================] - 0s 269us/sample - loss: 4.9987 - accuracy: 0.0574\n",
      "Epoch 9/500\n",
      "453/453 [==============================] - 0s 308us/sample - loss: 4.9642 - accuracy: 0.0640\n",
      "Epoch 10/500\n",
      "453/453 [==============================] - 0s 222us/sample - loss: 4.9241 - accuracy: 0.0530\n",
      "Epoch 11/500\n",
      "453/453 [==============================] - 0s 170us/sample - loss: 4.8766 - accuracy: 0.0552\n",
      "Epoch 12/500\n",
      "453/453 [==============================] - 0s 225us/sample - loss: 4.8301 - accuracy: 0.0574\n",
      "Epoch 13/500\n",
      "453/453 [==============================] - 0s 192us/sample - loss: 4.7774 - accuracy: 0.0552\n",
      "Epoch 14/500\n",
      "453/453 [==============================] - 0s 239us/sample - loss: 4.7207 - accuracy: 0.0706\n",
      "Epoch 15/500\n",
      "453/453 [==============================] - 0s 192us/sample - loss: 4.6561 - accuracy: 0.0751\n",
      "Epoch 16/500\n",
      "453/453 [==============================] - 0s 297us/sample - loss: 4.5965 - accuracy: 0.0728\n",
      "Epoch 17/500\n",
      "453/453 [==============================] - 0s 187us/sample - loss: 4.5376 - accuracy: 0.0817\n",
      "Epoch 18/500\n",
      "453/453 [==============================] - 0s 183us/sample - loss: 4.4938 - accuracy: 0.0751\n",
      "Epoch 19/500\n",
      "453/453 [==============================] - 0s 230us/sample - loss: 4.4413 - accuracy: 0.0883\n",
      "Epoch 20/500\n",
      "453/453 [==============================] - 0s 260us/sample - loss: 4.3979 - accuracy: 0.0971\n",
      "Epoch 21/500\n",
      "453/453 [==============================] - 0s 187us/sample - loss: 4.3502 - accuracy: 0.0927\n",
      "Epoch 22/500\n",
      "453/453 [==============================] - 0s 211us/sample - loss: 4.3036 - accuracy: 0.0971\n",
      "Epoch 23/500\n",
      "453/453 [==============================] - 0s 200us/sample - loss: 4.2681 - accuracy: 0.1038\n",
      "Epoch 24/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 4.2256 - accuracy: 0.1082\n",
      "Epoch 25/500\n",
      "453/453 [==============================] - 0s 176us/sample - loss: 4.1819 - accuracy: 0.1082\n",
      "Epoch 26/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 4.1456 - accuracy: 0.1126\n",
      "Epoch 27/500\n",
      "453/453 [==============================] - 0s 170us/sample - loss: 4.1041 - accuracy: 0.1280\n",
      "Epoch 28/500\n",
      "453/453 [==============================] - 0s 167us/sample - loss: 4.0684 - accuracy: 0.1391\n",
      "Epoch 29/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 4.0188 - accuracy: 0.1457\n",
      "Epoch 30/500\n",
      "453/453 [==============================] - 0s 174us/sample - loss: 3.9848 - accuracy: 0.1435\n",
      "Epoch 31/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 3.9448 - accuracy: 0.1413\n",
      "Epoch 32/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 3.9059 - accuracy: 0.1567\n",
      "Epoch 33/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 3.8549 - accuracy: 0.1611\n",
      "Epoch 34/500\n",
      "453/453 [==============================] - 0s 162us/sample - loss: 3.8163 - accuracy: 0.1744\n",
      "Epoch 35/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 3.7851 - accuracy: 0.1744\n",
      "Epoch 36/500\n",
      "453/453 [==============================] - 0s 185us/sample - loss: 3.7453 - accuracy: 0.1876\n",
      "Epoch 37/500\n",
      "453/453 [==============================] - 0s 180us/sample - loss: 3.7087 - accuracy: 0.2009\n",
      "Epoch 38/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 3.6851 - accuracy: 0.2053\n",
      "Epoch 39/500\n",
      "453/453 [==============================] - 0s 160us/sample - loss: 3.6318 - accuracy: 0.2097\n",
      "Epoch 40/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 3.6000 - accuracy: 0.2296\n",
      "Epoch 41/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 3.5632 - accuracy: 0.2428\n",
      "Epoch 42/500\n",
      "453/453 [==============================] - 0s 152us/sample - loss: 3.5390 - accuracy: 0.2450\n",
      "Epoch 43/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 3.4907 - accuracy: 0.2693\n",
      "Epoch 44/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 3.4489 - accuracy: 0.2781\n",
      "Epoch 45/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 3.4094 - accuracy: 0.2892\n",
      "Epoch 46/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 3.3750 - accuracy: 0.2914\n",
      "Epoch 47/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 3.3400 - accuracy: 0.3245\n",
      "Epoch 48/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 3.3096 - accuracy: 0.3201\n",
      "Epoch 49/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 3.2705 - accuracy: 0.3201\n",
      "Epoch 50/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 3.2499 - accuracy: 0.3223\n",
      "Epoch 51/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 3.2115 - accuracy: 0.3245\n",
      "Epoch 52/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 3.1744 - accuracy: 0.3267\n",
      "Epoch 53/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 3.1440 - accuracy: 0.3333\n",
      "Epoch 54/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 3.1124 - accuracy: 0.3311\n",
      "Epoch 55/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 3.0730 - accuracy: 0.3576\n",
      "Epoch 56/500\n",
      "453/453 [==============================] - 0s 167us/sample - loss: 3.0384 - accuracy: 0.3620\n",
      "Epoch 57/500\n",
      "453/453 [==============================] - 0s 152us/sample - loss: 3.0095 - accuracy: 0.3731\n",
      "Epoch 58/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 2.9862 - accuracy: 0.3642\n",
      "Epoch 59/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 2.9518 - accuracy: 0.3709\n",
      "Epoch 60/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 2.9216 - accuracy: 0.3841\n",
      "Epoch 61/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 2.8968 - accuracy: 0.3775\n",
      "Epoch 62/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 2.8633 - accuracy: 0.3841\n",
      "Epoch 63/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 2.8493 - accuracy: 0.3996\n",
      "Epoch 64/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 2.8088 - accuracy: 0.3974\n",
      "Epoch 65/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 2.7743 - accuracy: 0.4172\n",
      "Epoch 66/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 2.7412 - accuracy: 0.4327\n",
      "Epoch 67/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 2.7135 - accuracy: 0.4283\n",
      "Epoch 68/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 2.6947 - accuracy: 0.4305\n",
      "Epoch 69/500\n",
      "453/453 [==============================] - 0s 145us/sample - loss: 2.6743 - accuracy: 0.4393\n",
      "Epoch 70/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 2.6552 - accuracy: 0.4570\n",
      "Epoch 71/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 2.6259 - accuracy: 0.4437\n",
      "Epoch 72/500\n",
      "453/453 [==============================] - 0s 150us/sample - loss: 2.6111 - accuracy: 0.4570\n",
      "Epoch 73/500\n",
      "453/453 [==============================] - 0s 148us/sample - loss: 2.6089 - accuracy: 0.4658\n",
      "Epoch 74/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 2.5788 - accuracy: 0.4790\n",
      "Epoch 75/500\n",
      "453/453 [==============================] - 0s 149us/sample - loss: 2.5385 - accuracy: 0.4702\n",
      "Epoch 76/500\n",
      "453/453 [==============================] - 0s 152us/sample - loss: 2.5071 - accuracy: 0.5033\n",
      "Epoch 77/500\n",
      "453/453 [==============================] - 0s 148us/sample - loss: 2.4832 - accuracy: 0.4812\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 143us/sample - loss: 2.4572 - accuracy: 0.5011\n",
      "Epoch 79/500\n",
      "453/453 [==============================] - 0s 149us/sample - loss: 2.4376 - accuracy: 0.5166\n",
      "Epoch 80/500\n",
      "453/453 [==============================] - 0s 147us/sample - loss: 2.3949 - accuracy: 0.5254\n",
      "Epoch 81/500\n",
      "453/453 [==============================] - 0s 150us/sample - loss: 2.3649 - accuracy: 0.5453\n",
      "Epoch 82/500\n",
      "453/453 [==============================] - 0s 145us/sample - loss: 2.3390 - accuracy: 0.5541\n",
      "Epoch 83/500\n",
      "453/453 [==============================] - 0s 149us/sample - loss: 2.3193 - accuracy: 0.5651\n",
      "Epoch 84/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 2.2913 - accuracy: 0.5784\n",
      "Epoch 85/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 2.2738 - accuracy: 0.5894\n",
      "Epoch 86/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 2.2595 - accuracy: 0.5960\n",
      "Epoch 87/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 2.2414 - accuracy: 0.5828\n",
      "Epoch 88/500\n",
      "453/453 [==============================] - 0s 151us/sample - loss: 2.2129 - accuracy: 0.5982\n",
      "Epoch 89/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 2.1951 - accuracy: 0.5872\n",
      "Epoch 90/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 2.1700 - accuracy: 0.5938\n",
      "Epoch 91/500\n",
      "453/453 [==============================] - 0s 145us/sample - loss: 2.1456 - accuracy: 0.5938\n",
      "Epoch 92/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 2.1363 - accuracy: 0.5938\n",
      "Epoch 93/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 2.1105 - accuracy: 0.5916\n",
      "Epoch 94/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 2.1088 - accuracy: 0.6071\n",
      "Epoch 95/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 2.1149 - accuracy: 0.6115\n",
      "Epoch 96/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 2.0852 - accuracy: 0.6115\n",
      "Epoch 97/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 2.0651 - accuracy: 0.6137\n",
      "Epoch 98/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 2.0402 - accuracy: 0.6225\n",
      "Epoch 99/500\n",
      "453/453 [==============================] - 0s 140us/sample - loss: 2.0273 - accuracy: 0.6137\n",
      "Epoch 100/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 2.0149 - accuracy: 0.6225\n",
      "Epoch 101/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 2.0033 - accuracy: 0.6269\n",
      "Epoch 102/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 1.9666 - accuracy: 0.6336\n",
      "Epoch 103/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 1.9323 - accuracy: 0.6424\n",
      "Epoch 104/500\n",
      "453/453 [==============================] - 0s 176us/sample - loss: 1.9133 - accuracy: 0.6512\n",
      "Epoch 105/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 1.8959 - accuracy: 0.6711\n",
      "Epoch 106/500\n",
      "453/453 [==============================] - 0s 170us/sample - loss: 1.8768 - accuracy: 0.6667\n",
      "Epoch 107/500\n",
      "453/453 [==============================] - 0s 170us/sample - loss: 1.8587 - accuracy: 0.6777\n",
      "Epoch 108/500\n",
      "453/453 [==============================] - 0s 176us/sample - loss: 1.8499 - accuracy: 0.6755\n",
      "Epoch 109/500\n",
      "453/453 [==============================] - 0s 176us/sample - loss: 1.8140 - accuracy: 0.6843\n",
      "Epoch 110/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 1.7923 - accuracy: 0.6932\n",
      "Epoch 111/500\n",
      "453/453 [==============================] - 0s 152us/sample - loss: 1.7779 - accuracy: 0.6887\n",
      "Epoch 112/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 1.7576 - accuracy: 0.7064\n",
      "Epoch 113/500\n",
      "453/453 [==============================] - 0s 152us/sample - loss: 1.7388 - accuracy: 0.7064\n",
      "Epoch 114/500\n",
      "453/453 [==============================] - 0s 152us/sample - loss: 1.7215 - accuracy: 0.7130\n",
      "Epoch 115/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 1.7035 - accuracy: 0.7196\n",
      "Epoch 116/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 1.6851 - accuracy: 0.7196\n",
      "Epoch 117/500\n",
      "453/453 [==============================] - 0s 155us/sample - loss: 1.6621 - accuracy: 0.7241\n",
      "Epoch 118/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 1.6433 - accuracy: 0.7219\n",
      "Epoch 119/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 1.6272 - accuracy: 0.7263\n",
      "Epoch 120/500\n",
      "453/453 [==============================] - 0s 155us/sample - loss: 1.6192 - accuracy: 0.7241\n",
      "Epoch 121/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 1.6095 - accuracy: 0.7373\n",
      "Epoch 122/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 1.5897 - accuracy: 0.7395\n",
      "Epoch 123/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 1.5683 - accuracy: 0.7550\n",
      "Epoch 124/500\n",
      "453/453 [==============================] - 0s 153us/sample - loss: 1.5514 - accuracy: 0.7660\n",
      "Epoch 125/500\n",
      "453/453 [==============================] - 0s 151us/sample - loss: 1.5420 - accuracy: 0.7660\n",
      "Epoch 126/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 1.5302 - accuracy: 0.7726\n",
      "Epoch 127/500\n",
      "453/453 [==============================] - 0s 158us/sample - loss: 1.5119 - accuracy: 0.7837\n",
      "Epoch 128/500\n",
      "453/453 [==============================] - 0s 228us/sample - loss: 1.4980 - accuracy: 0.7770\n",
      "Epoch 129/500\n",
      "453/453 [==============================] - 0s 184us/sample - loss: 1.4795 - accuracy: 0.7770\n",
      "Epoch 130/500\n",
      "453/453 [==============================] - 0s 167us/sample - loss: 1.4603 - accuracy: 0.7881\n",
      "Epoch 131/500\n",
      "453/453 [==============================] - 0s 170us/sample - loss: 1.4558 - accuracy: 0.7859\n",
      "Epoch 132/500\n",
      "453/453 [==============================] - 0s 172us/sample - loss: 1.4384 - accuracy: 0.7837\n",
      "Epoch 133/500\n",
      "453/453 [==============================] - 0s 203us/sample - loss: 1.4200 - accuracy: 0.7881\n",
      "Epoch 134/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 1.4090 - accuracy: 0.7881\n",
      "Epoch 135/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 1.3937 - accuracy: 0.7925\n",
      "Epoch 136/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 1.3800 - accuracy: 0.7947\n",
      "Epoch 137/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 1.3648 - accuracy: 0.7969\n",
      "Epoch 138/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 1.3484 - accuracy: 0.7991\n",
      "Epoch 139/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 1.3556 - accuracy: 0.7947\n",
      "Epoch 140/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 1.3493 - accuracy: 0.7969\n",
      "Epoch 141/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 1.3347 - accuracy: 0.7969\n",
      "Epoch 142/500\n",
      "453/453 [==============================] - 0s 160us/sample - loss: 1.3245 - accuracy: 0.7881\n",
      "Epoch 143/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 1.3065 - accuracy: 0.7947\n",
      "Epoch 144/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 1.2893 - accuracy: 0.7947\n",
      "Epoch 145/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 1.2742 - accuracy: 0.8102\n",
      "Epoch 146/500\n",
      "453/453 [==============================] - 0s 202us/sample - loss: 1.2595 - accuracy: 0.7991\n",
      "Epoch 147/500\n",
      "453/453 [==============================] - 0s 162us/sample - loss: 1.2460 - accuracy: 0.8079\n",
      "Epoch 148/500\n",
      "453/453 [==============================] - 0s 187us/sample - loss: 1.2462 - accuracy: 0.7969\n",
      "Epoch 149/500\n",
      "453/453 [==============================] - 0s 160us/sample - loss: 1.2468 - accuracy: 0.8013\n",
      "Epoch 150/500\n",
      "453/453 [==============================] - 0s 192us/sample - loss: 1.2366 - accuracy: 0.7969\n",
      "Epoch 151/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 1.2171 - accuracy: 0.7947\n",
      "Epoch 152/500\n",
      "453/453 [==============================] - 0s 174us/sample - loss: 1.2064 - accuracy: 0.8057\n",
      "Epoch 153/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 1.1985 - accuracy: 0.8146\n",
      "Epoch 154/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 161us/sample - loss: 1.1829 - accuracy: 0.8168\n",
      "Epoch 155/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 1.1767 - accuracy: 0.8124\n",
      "Epoch 156/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 1.1532 - accuracy: 0.8300\n",
      "Epoch 157/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 1.1340 - accuracy: 0.8300\n",
      "Epoch 158/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 1.1188 - accuracy: 0.8389\n",
      "Epoch 159/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 1.0999 - accuracy: 0.8389\n",
      "Epoch 160/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 1.0913 - accuracy: 0.8433\n",
      "Epoch 161/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 1.0824 - accuracy: 0.8433\n",
      "Epoch 162/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 1.0683 - accuracy: 0.8411\n",
      "Epoch 163/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 1.0681 - accuracy: 0.8389\n",
      "Epoch 164/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 1.0599 - accuracy: 0.8411\n",
      "Epoch 165/500\n",
      "453/453 [==============================] - 0s 160us/sample - loss: 1.0399 - accuracy: 0.8521\n",
      "Epoch 166/500\n",
      "453/453 [==============================] - 0s 158us/sample - loss: 1.0288 - accuracy: 0.8521\n",
      "Epoch 167/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 1.0170 - accuracy: 0.8565\n",
      "Epoch 168/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 1.0068 - accuracy: 0.8631\n",
      "Epoch 169/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 1.0019 - accuracy: 0.8609\n",
      "Epoch 170/500\n",
      "453/453 [==============================] - 0s 164us/sample - loss: 0.9884 - accuracy: 0.8543\n",
      "Epoch 171/500\n",
      "453/453 [==============================] - 0s 173us/sample - loss: 0.9828 - accuracy: 0.8587\n",
      "Epoch 172/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 1.0087 - accuracy: 0.8565\n",
      "Epoch 173/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 0.9843 - accuracy: 0.8521\n",
      "Epoch 174/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 0.9979 - accuracy: 0.8411\n",
      "Epoch 175/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 0.9822 - accuracy: 0.8543\n",
      "Epoch 176/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.9753 - accuracy: 0.8366\n",
      "Epoch 177/500\n",
      "453/453 [==============================] - 0s 167us/sample - loss: 0.9589 - accuracy: 0.8587\n",
      "Epoch 178/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.9419 - accuracy: 0.8653\n",
      "Epoch 179/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.9308 - accuracy: 0.8587\n",
      "Epoch 180/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.9184 - accuracy: 0.8720\n",
      "Epoch 181/500\n",
      "453/453 [==============================] - 0s 158us/sample - loss: 0.9017 - accuracy: 0.8609\n",
      "Epoch 182/500\n",
      "453/453 [==============================] - 0s 194us/sample - loss: 0.8926 - accuracy: 0.8698\n",
      "Epoch 183/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.8838 - accuracy: 0.8698\n",
      "Epoch 184/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.8743 - accuracy: 0.8653\n",
      "Epoch 185/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.8669 - accuracy: 0.8653\n",
      "Epoch 186/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.8811 - accuracy: 0.8653\n",
      "Epoch 187/500\n",
      "453/453 [==============================] - 0s 158us/sample - loss: 0.8750 - accuracy: 0.8742\n",
      "Epoch 188/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.8639 - accuracy: 0.8653\n",
      "Epoch 189/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.8556 - accuracy: 0.8631\n",
      "Epoch 190/500\n",
      "453/453 [==============================] - 0s 172us/sample - loss: 0.8378 - accuracy: 0.8631\n",
      "Epoch 191/500\n",
      "453/453 [==============================] - 0s 164us/sample - loss: 0.8217 - accuracy: 0.8808\n",
      "Epoch 192/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.8128 - accuracy: 0.8764\n",
      "Epoch 193/500\n",
      "453/453 [==============================] - 0s 181us/sample - loss: 0.8032 - accuracy: 0.8764\n",
      "Epoch 194/500\n",
      "453/453 [==============================] - 0s 172us/sample - loss: 0.7961 - accuracy: 0.8808\n",
      "Epoch 195/500\n",
      "453/453 [==============================] - 0s 146us/sample - loss: 0.7848 - accuracy: 0.8852\n",
      "Epoch 196/500\n",
      "453/453 [==============================] - 0s 152us/sample - loss: 0.7795 - accuracy: 0.8786\n",
      "Epoch 197/500\n",
      "453/453 [==============================] - 0s 181us/sample - loss: 0.7737 - accuracy: 0.8808\n",
      "Epoch 198/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 0.7637 - accuracy: 0.8852\n",
      "Epoch 199/500\n",
      "453/453 [==============================] - 0s 174us/sample - loss: 0.7625 - accuracy: 0.8852\n",
      "Epoch 200/500\n",
      "453/453 [==============================] - 0s 174us/sample - loss: 0.7560 - accuracy: 0.8918\n",
      "Epoch 201/500\n",
      "453/453 [==============================] - 0s 181us/sample - loss: 0.7596 - accuracy: 0.8896\n",
      "Epoch 202/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 0.7713 - accuracy: 0.8874\n",
      "Epoch 203/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.7514 - accuracy: 0.8874\n",
      "Epoch 204/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 0.7404 - accuracy: 0.8985\n",
      "Epoch 205/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.7285 - accuracy: 0.9029\n",
      "Epoch 206/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.7194 - accuracy: 0.8962\n",
      "Epoch 207/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.7114 - accuracy: 0.9007\n",
      "Epoch 208/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.7087 - accuracy: 0.8962\n",
      "Epoch 209/500\n",
      "453/453 [==============================] - 0s 160us/sample - loss: 0.7038 - accuracy: 0.9029\n",
      "Epoch 210/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.6911 - accuracy: 0.8985\n",
      "Epoch 211/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.6865 - accuracy: 0.8985\n",
      "Epoch 212/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.6744 - accuracy: 0.9051\n",
      "Epoch 213/500\n",
      "453/453 [==============================] - 0s 162us/sample - loss: 0.6683 - accuracy: 0.9007\n",
      "Epoch 214/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.6606 - accuracy: 0.9139\n",
      "Epoch 215/500\n",
      "453/453 [==============================] - 0s 189us/sample - loss: 0.6526 - accuracy: 0.9095\n",
      "Epoch 216/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.6465 - accuracy: 0.9073\n",
      "Epoch 217/500\n",
      "453/453 [==============================] - 0s 167us/sample - loss: 0.6428 - accuracy: 0.9117\n",
      "Epoch 218/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.6349 - accuracy: 0.9073\n",
      "Epoch 219/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.6274 - accuracy: 0.9139\n",
      "Epoch 220/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.6232 - accuracy: 0.9227\n",
      "Epoch 221/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.6164 - accuracy: 0.9205\n",
      "Epoch 222/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.6112 - accuracy: 0.9139\n",
      "Epoch 223/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.6098 - accuracy: 0.9205\n",
      "Epoch 224/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.5999 - accuracy: 0.9227\n",
      "Epoch 225/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.5937 - accuracy: 0.9183\n",
      "Epoch 226/500\n",
      "453/453 [==============================] - 0s 157us/sample - loss: 0.5889 - accuracy: 0.9161\n",
      "Epoch 227/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.5936 - accuracy: 0.9161\n",
      "Epoch 228/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.5842 - accuracy: 0.9205\n",
      "Epoch 229/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.5806 - accuracy: 0.9161\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 159us/sample - loss: 0.5744 - accuracy: 0.9183\n",
      "Epoch 231/500\n",
      "453/453 [==============================] - 0s 167us/sample - loss: 0.5721 - accuracy: 0.9227\n",
      "Epoch 232/500\n",
      "453/453 [==============================] - 0s 149us/sample - loss: 0.5663 - accuracy: 0.9294\n",
      "Epoch 233/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.5621 - accuracy: 0.9249\n",
      "Epoch 234/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.5540 - accuracy: 0.9272\n",
      "Epoch 235/500\n",
      "453/453 [==============================] - 0s 167us/sample - loss: 0.5492 - accuracy: 0.9294\n",
      "Epoch 236/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.5451 - accuracy: 0.9272\n",
      "Epoch 237/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.5430 - accuracy: 0.9272\n",
      "Epoch 238/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.5355 - accuracy: 0.9316\n",
      "Epoch 239/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.5296 - accuracy: 0.9316\n",
      "Epoch 240/500\n",
      "453/453 [==============================] - 0s 167us/sample - loss: 0.5266 - accuracy: 0.9360\n",
      "Epoch 241/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.5215 - accuracy: 0.9338\n",
      "Epoch 242/500\n",
      "453/453 [==============================] - 0s 174us/sample - loss: 0.5143 - accuracy: 0.9338\n",
      "Epoch 243/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.5119 - accuracy: 0.9316\n",
      "Epoch 244/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.5074 - accuracy: 0.9338\n",
      "Epoch 245/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.5023 - accuracy: 0.9316\n",
      "Epoch 246/500\n",
      "453/453 [==============================] - 0s 183us/sample - loss: 0.5004 - accuracy: 0.9338\n",
      "Epoch 247/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.4938 - accuracy: 0.9338\n",
      "Epoch 248/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.4886 - accuracy: 0.9316\n",
      "Epoch 249/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.4865 - accuracy: 0.9338\n",
      "Epoch 250/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.4864 - accuracy: 0.9360\n",
      "Epoch 251/500\n",
      "453/453 [==============================] - 0s 164us/sample - loss: 0.4807 - accuracy: 0.9360\n",
      "Epoch 252/500\n",
      "453/453 [==============================] - 0s 160us/sample - loss: 0.4779 - accuracy: 0.9316\n",
      "Epoch 253/500\n",
      "453/453 [==============================] - 0s 160us/sample - loss: 0.4764 - accuracy: 0.9316\n",
      "Epoch 254/500\n",
      "453/453 [==============================] - 0s 152us/sample - loss: 0.4788 - accuracy: 0.9316\n",
      "Epoch 255/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.4822 - accuracy: 0.9338\n",
      "Epoch 256/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.5016 - accuracy: 0.9249\n",
      "Epoch 257/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.4941 - accuracy: 0.9249\n",
      "Epoch 258/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.4969 - accuracy: 0.9249\n",
      "Epoch 259/500\n",
      "453/453 [==============================] - 0s 167us/sample - loss: 0.4889 - accuracy: 0.9294\n",
      "Epoch 260/500\n",
      "453/453 [==============================] - 0s 148us/sample - loss: 0.4927 - accuracy: 0.9294\n",
      "Epoch 261/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.4729 - accuracy: 0.9272\n",
      "Epoch 262/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.4581 - accuracy: 0.9294\n",
      "Epoch 263/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 0.4503 - accuracy: 0.9316\n",
      "Epoch 264/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.4418 - accuracy: 0.9338\n",
      "Epoch 265/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.4335 - accuracy: 0.9338\n",
      "Epoch 266/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.4314 - accuracy: 0.9316\n",
      "Epoch 267/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 0.4342 - accuracy: 0.9360\n",
      "Epoch 268/500\n",
      "453/453 [==============================] - 0s 148us/sample - loss: 0.4257 - accuracy: 0.9360\n",
      "Epoch 269/500\n",
      "453/453 [==============================] - 0s 145us/sample - loss: 0.4176 - accuracy: 0.9382\n",
      "Epoch 270/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.4149 - accuracy: 0.9382\n",
      "Epoch 271/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.4120 - accuracy: 0.9382\n",
      "Epoch 272/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.4138 - accuracy: 0.9404\n",
      "Epoch 273/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.4137 - accuracy: 0.9382\n",
      "Epoch 274/500\n",
      "453/453 [==============================] - 0s 144us/sample - loss: 0.4066 - accuracy: 0.9382\n",
      "Epoch 275/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.4016 - accuracy: 0.9382\n",
      "Epoch 276/500\n",
      "453/453 [==============================] - 0s 138us/sample - loss: 0.3976 - accuracy: 0.9382\n",
      "Epoch 277/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 0.3936 - accuracy: 0.9404\n",
      "Epoch 278/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.3904 - accuracy: 0.9404\n",
      "Epoch 279/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.3882 - accuracy: 0.9404\n",
      "Epoch 280/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 0.3850 - accuracy: 0.9426\n",
      "Epoch 281/500\n",
      "453/453 [==============================] - 0s 170us/sample - loss: 0.3843 - accuracy: 0.9426\n",
      "Epoch 282/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.3796 - accuracy: 0.9404\n",
      "Epoch 283/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.3935 - accuracy: 0.9404\n",
      "Epoch 284/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.4146 - accuracy: 0.9338\n",
      "Epoch 285/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.4178 - accuracy: 0.9272\n",
      "Epoch 286/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.4073 - accuracy: 0.9294\n",
      "Epoch 287/500\n",
      "453/453 [==============================] - 0s 152us/sample - loss: 0.3994 - accuracy: 0.9338\n",
      "Epoch 288/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.3881 - accuracy: 0.9360\n",
      "Epoch 289/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.4127 - accuracy: 0.9294\n",
      "Epoch 290/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.4365 - accuracy: 0.9161\n",
      "Epoch 291/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.3917 - accuracy: 0.9360\n",
      "Epoch 292/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.3894 - accuracy: 0.9338\n",
      "Epoch 293/500\n",
      "453/453 [==============================] - 0s 150us/sample - loss: 0.3776 - accuracy: 0.9382\n",
      "Epoch 294/500\n",
      "453/453 [==============================] - 0s 167us/sample - loss: 0.3700 - accuracy: 0.9404\n",
      "Epoch 295/500\n",
      "453/453 [==============================] - 0s 169us/sample - loss: 0.3609 - accuracy: 0.9448\n",
      "Epoch 296/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.3494 - accuracy: 0.9448\n",
      "Epoch 297/500\n",
      "453/453 [==============================] - 0s 162us/sample - loss: 0.3452 - accuracy: 0.9426\n",
      "Epoch 298/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.3423 - accuracy: 0.9448\n",
      "Epoch 299/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.3384 - accuracy: 0.9426\n",
      "Epoch 300/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.3384 - accuracy: 0.9404\n",
      "Epoch 301/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.3330 - accuracy: 0.9404\n",
      "Epoch 302/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.3302 - accuracy: 0.9426\n",
      "Epoch 303/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.3269 - accuracy: 0.9448\n",
      "Epoch 304/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 0.3266 - accuracy: 0.9404\n",
      "Epoch 305/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.3224 - accuracy: 0.9448\n",
      "Epoch 306/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 148us/sample - loss: 0.3204 - accuracy: 0.9448\n",
      "Epoch 307/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.3184 - accuracy: 0.9448\n",
      "Epoch 308/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 0.3153 - accuracy: 0.9448\n",
      "Epoch 309/500\n",
      "453/453 [==============================] - 0s 152us/sample - loss: 0.3131 - accuracy: 0.9426\n",
      "Epoch 310/500\n",
      "453/453 [==============================] - 0s 145us/sample - loss: 0.3116 - accuracy: 0.9448\n",
      "Epoch 311/500\n",
      "453/453 [==============================] - 0s 148us/sample - loss: 0.3093 - accuracy: 0.9470\n",
      "Epoch 312/500\n",
      "453/453 [==============================] - 0s 149us/sample - loss: 0.3067 - accuracy: 0.9470\n",
      "Epoch 313/500\n",
      "453/453 [==============================] - 0s 145us/sample - loss: 0.3059 - accuracy: 0.9470\n",
      "Epoch 314/500\n",
      "453/453 [==============================] - 0s 142us/sample - loss: 0.3034 - accuracy: 0.9470\n",
      "Epoch 315/500\n",
      "453/453 [==============================] - 0s 145us/sample - loss: 0.3015 - accuracy: 0.9470\n",
      "Epoch 316/500\n",
      "453/453 [==============================] - 0s 144us/sample - loss: 0.3039 - accuracy: 0.9426\n",
      "Epoch 317/500\n",
      "453/453 [==============================] - 0s 148us/sample - loss: 0.2984 - accuracy: 0.9470\n",
      "Epoch 318/500\n",
      "453/453 [==============================] - 0s 140us/sample - loss: 0.2964 - accuracy: 0.9492\n",
      "Epoch 319/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.2933 - accuracy: 0.9492\n",
      "Epoch 320/500\n",
      "453/453 [==============================] - 0s 140us/sample - loss: 0.2923 - accuracy: 0.9470\n",
      "Epoch 321/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 0.2914 - accuracy: 0.9492\n",
      "Epoch 322/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.2942 - accuracy: 0.9426\n",
      "Epoch 323/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.2906 - accuracy: 0.9448\n",
      "Epoch 324/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 0.2970 - accuracy: 0.9470\n",
      "Epoch 325/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.2995 - accuracy: 0.9382\n",
      "Epoch 326/500\n",
      "453/453 [==============================] - 0s 150us/sample - loss: 0.3026 - accuracy: 0.9360\n",
      "Epoch 327/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 0.3020 - accuracy: 0.9404\n",
      "Epoch 328/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.2889 - accuracy: 0.9426\n",
      "Epoch 329/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.2822 - accuracy: 0.9448\n",
      "Epoch 330/500\n",
      "453/453 [==============================] - 0s 170us/sample - loss: 0.2803 - accuracy: 0.9470\n",
      "Epoch 331/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.2779 - accuracy: 0.9492\n",
      "Epoch 332/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.2746 - accuracy: 0.9492\n",
      "Epoch 333/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.2717 - accuracy: 0.9448\n",
      "Epoch 334/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 0.2692 - accuracy: 0.9448\n",
      "Epoch 335/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.2680 - accuracy: 0.9470\n",
      "Epoch 336/500\n",
      "453/453 [==============================] - 0s 153us/sample - loss: 0.2658 - accuracy: 0.9448\n",
      "Epoch 337/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 0.2646 - accuracy: 0.9470\n",
      "Epoch 338/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.2634 - accuracy: 0.9448\n",
      "Epoch 339/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.2611 - accuracy: 0.9470\n",
      "Epoch 340/500\n",
      "453/453 [==============================] - 0s 160us/sample - loss: 0.2595 - accuracy: 0.9448\n",
      "Epoch 341/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.2579 - accuracy: 0.9470\n",
      "Epoch 342/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.2571 - accuracy: 0.9492\n",
      "Epoch 343/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.2569 - accuracy: 0.9426\n",
      "Epoch 344/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.2546 - accuracy: 0.9448\n",
      "Epoch 345/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.2511 - accuracy: 0.9448\n",
      "Epoch 346/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 0.2497 - accuracy: 0.9448\n",
      "Epoch 347/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.2490 - accuracy: 0.9492\n",
      "Epoch 348/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.2472 - accuracy: 0.9492\n",
      "Epoch 349/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.2459 - accuracy: 0.9492\n",
      "Epoch 350/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.2446 - accuracy: 0.9404\n",
      "Epoch 351/500\n",
      "453/453 [==============================] - 0s 170us/sample - loss: 0.2423 - accuracy: 0.9470\n",
      "Epoch 352/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.2414 - accuracy: 0.9514\n",
      "Epoch 353/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 0.2389 - accuracy: 0.9514\n",
      "Epoch 354/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 0.2379 - accuracy: 0.9492\n",
      "Epoch 355/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 0.2375 - accuracy: 0.9514\n",
      "Epoch 356/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.2364 - accuracy: 0.9514\n",
      "Epoch 357/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.2368 - accuracy: 0.9470\n",
      "Epoch 358/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.2344 - accuracy: 0.9448\n",
      "Epoch 359/500\n",
      "453/453 [==============================] - 0s 140us/sample - loss: 0.2326 - accuracy: 0.9448\n",
      "Epoch 360/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.2305 - accuracy: 0.9492\n",
      "Epoch 361/500\n",
      "453/453 [==============================] - 0s 148us/sample - loss: 0.2295 - accuracy: 0.9470\n",
      "Epoch 362/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.2286 - accuracy: 0.9448\n",
      "Epoch 363/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 0.2283 - accuracy: 0.9470\n",
      "Epoch 364/500\n",
      "453/453 [==============================] - 0s 142us/sample - loss: 0.2274 - accuracy: 0.9492\n",
      "Epoch 365/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.2246 - accuracy: 0.9470\n",
      "Epoch 366/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.2237 - accuracy: 0.9448\n",
      "Epoch 367/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.2235 - accuracy: 0.9492\n",
      "Epoch 368/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 0.2202 - accuracy: 0.9536\n",
      "Epoch 369/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.2207 - accuracy: 0.9470\n",
      "Epoch 370/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 0.2195 - accuracy: 0.9514\n",
      "Epoch 371/500\n",
      "453/453 [==============================] - 0s 142us/sample - loss: 0.2191 - accuracy: 0.9470\n",
      "Epoch 372/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.2167 - accuracy: 0.9514\n",
      "Epoch 373/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.2155 - accuracy: 0.9492\n",
      "Epoch 374/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.2142 - accuracy: 0.9448\n",
      "Epoch 375/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.2130 - accuracy: 0.9514\n",
      "Epoch 376/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.2114 - accuracy: 0.9426\n",
      "Epoch 377/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 0.2104 - accuracy: 0.9470\n",
      "Epoch 378/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 0.2094 - accuracy: 0.9492\n",
      "Epoch 379/500\n",
      "453/453 [==============================] - 0s 179us/sample - loss: 0.2087 - accuracy: 0.9448\n",
      "Epoch 380/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 0.2070 - accuracy: 0.9448\n",
      "Epoch 381/500\n",
      "453/453 [==============================] - 0s 145us/sample - loss: 0.2075 - accuracy: 0.9470\n",
      "Epoch 382/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 148us/sample - loss: 0.2055 - accuracy: 0.9470\n",
      "Epoch 383/500\n",
      "453/453 [==============================] - 0s 142us/sample - loss: 0.2051 - accuracy: 0.9470\n",
      "Epoch 384/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 0.2032 - accuracy: 0.9470\n",
      "Epoch 385/500\n",
      "453/453 [==============================] - 0s 145us/sample - loss: 0.2016 - accuracy: 0.9492\n",
      "Epoch 386/500\n",
      "453/453 [==============================] - 0s 148us/sample - loss: 0.2006 - accuracy: 0.9514\n",
      "Epoch 387/500\n",
      "453/453 [==============================] - 0s 152us/sample - loss: 0.1998 - accuracy: 0.9448\n",
      "Epoch 388/500\n",
      "453/453 [==============================] - 0s 169us/sample - loss: 0.1992 - accuracy: 0.9448\n",
      "Epoch 389/500\n",
      "453/453 [==============================] - 0s 167us/sample - loss: 0.1973 - accuracy: 0.9448\n",
      "Epoch 390/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.1979 - accuracy: 0.9470\n",
      "Epoch 391/500\n",
      "453/453 [==============================] - 0s 167us/sample - loss: 0.1991 - accuracy: 0.9536\n",
      "Epoch 392/500\n",
      "453/453 [==============================] - 0s 172us/sample - loss: 0.2104 - accuracy: 0.9514\n",
      "Epoch 393/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.2049 - accuracy: 0.9492\n",
      "Epoch 394/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.2002 - accuracy: 0.9470\n",
      "Epoch 395/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.1956 - accuracy: 0.9514\n",
      "Epoch 396/500\n",
      "453/453 [==============================] - 0s 152us/sample - loss: 0.1937 - accuracy: 0.9492\n",
      "Epoch 397/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.1919 - accuracy: 0.9514\n",
      "Epoch 398/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.1912 - accuracy: 0.9470\n",
      "Epoch 399/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.1910 - accuracy: 0.9514\n",
      "Epoch 400/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.1902 - accuracy: 0.9514\n",
      "Epoch 401/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.1897 - accuracy: 0.9536\n",
      "Epoch 402/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.1888 - accuracy: 0.9404\n",
      "Epoch 403/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.1876 - accuracy: 0.9492\n",
      "Epoch 404/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.1861 - accuracy: 0.9514\n",
      "Epoch 405/500\n",
      "453/453 [==============================] - 0s 142us/sample - loss: 0.1844 - accuracy: 0.9470\n",
      "Epoch 406/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 0.1838 - accuracy: 0.9514\n",
      "Epoch 407/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.1830 - accuracy: 0.9404\n",
      "Epoch 408/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.1819 - accuracy: 0.9448\n",
      "Epoch 409/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.1809 - accuracy: 0.9426\n",
      "Epoch 410/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.1811 - accuracy: 0.9470\n",
      "Epoch 411/500\n",
      "453/453 [==============================] - 0s 148us/sample - loss: 0.1793 - accuracy: 0.9492\n",
      "Epoch 412/500\n",
      "453/453 [==============================] - 0s 183us/sample - loss: 0.1791 - accuracy: 0.9492\n",
      "Epoch 413/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.1784 - accuracy: 0.9492\n",
      "Epoch 414/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.1791 - accuracy: 0.9470\n",
      "Epoch 415/500\n",
      "453/453 [==============================] - 0s 174us/sample - loss: 0.1775 - accuracy: 0.9470\n",
      "Epoch 416/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.1778 - accuracy: 0.9470\n",
      "Epoch 417/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 0.1772 - accuracy: 0.9492\n",
      "Epoch 418/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.1760 - accuracy: 0.9448\n",
      "Epoch 419/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.1841 - accuracy: 0.9492\n",
      "Epoch 420/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.2107 - accuracy: 0.9448\n",
      "Epoch 421/500\n",
      "453/453 [==============================] - 0s 157us/sample - loss: 0.2514 - accuracy: 0.9316\n",
      "Epoch 422/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.2602 - accuracy: 0.9360\n",
      "Epoch 423/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 0.2906 - accuracy: 0.9205\n",
      "Epoch 424/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.2790 - accuracy: 0.9272\n",
      "Epoch 425/500\n",
      "453/453 [==============================] - 0s 167us/sample - loss: 0.2409 - accuracy: 0.9404\n",
      "Epoch 426/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.2119 - accuracy: 0.9426\n",
      "Epoch 427/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.1942 - accuracy: 0.9448\n",
      "Epoch 428/500\n",
      "453/453 [==============================] - 0s 183us/sample - loss: 0.1864 - accuracy: 0.9448\n",
      "Epoch 429/500\n",
      "453/453 [==============================] - 0s 172us/sample - loss: 0.1831 - accuracy: 0.9492\n",
      "Epoch 430/500\n",
      "453/453 [==============================] - 0s 166us/sample - loss: 0.1784 - accuracy: 0.9448\n",
      "Epoch 431/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 0.1761 - accuracy: 0.9470\n",
      "Epoch 432/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.1747 - accuracy: 0.9492\n",
      "Epoch 433/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.1729 - accuracy: 0.9426\n",
      "Epoch 434/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.1727 - accuracy: 0.9448\n",
      "Epoch 435/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.1699 - accuracy: 0.9492\n",
      "Epoch 436/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 0.1668 - accuracy: 0.9514\n",
      "Epoch 437/500\n",
      "453/453 [==============================] - 0s 168us/sample - loss: 0.1657 - accuracy: 0.9514\n",
      "Epoch 438/500\n",
      "453/453 [==============================] - 0s 176us/sample - loss: 0.1646 - accuracy: 0.9492\n",
      "Epoch 439/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 0.1634 - accuracy: 0.9536\n",
      "Epoch 440/500\n",
      "453/453 [==============================] - 0s 205us/sample - loss: 0.1636 - accuracy: 0.9492\n",
      "Epoch 441/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.1623 - accuracy: 0.9470\n",
      "Epoch 442/500\n",
      "453/453 [==============================] - 0s 191us/sample - loss: 0.1619 - accuracy: 0.9492\n",
      "Epoch 443/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.1614 - accuracy: 0.9470\n",
      "Epoch 444/500\n",
      "453/453 [==============================] - 0s 180us/sample - loss: 0.1599 - accuracy: 0.9492\n",
      "Epoch 445/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.1596 - accuracy: 0.9492\n",
      "Epoch 446/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.1593 - accuracy: 0.9492\n",
      "Epoch 447/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.1580 - accuracy: 0.9492\n",
      "Epoch 448/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.1577 - accuracy: 0.9492\n",
      "Epoch 449/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.1572 - accuracy: 0.9492\n",
      "Epoch 450/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.1557 - accuracy: 0.9470\n",
      "Epoch 451/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.1553 - accuracy: 0.9470\n",
      "Epoch 452/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.1545 - accuracy: 0.9536\n",
      "Epoch 453/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.1538 - accuracy: 0.9536\n",
      "Epoch 454/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.1533 - accuracy: 0.9492\n",
      "Epoch 455/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 0.1540 - accuracy: 0.9514\n",
      "Epoch 456/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.1522 - accuracy: 0.9492\n",
      "Epoch 457/500\n",
      "453/453 [==============================] - 0s 171us/sample - loss: 0.1526 - accuracy: 0.9448\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 163us/sample - loss: 0.1516 - accuracy: 0.9536\n",
      "Epoch 459/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 0.1516 - accuracy: 0.9470\n",
      "Epoch 460/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.1503 - accuracy: 0.9514\n",
      "Epoch 461/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 0.1511 - accuracy: 0.9448\n",
      "Epoch 462/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.1509 - accuracy: 0.9492\n",
      "Epoch 463/500\n",
      "453/453 [==============================] - 0s 158us/sample - loss: 0.1506 - accuracy: 0.9470\n",
      "Epoch 464/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.1487 - accuracy: 0.9514\n",
      "Epoch 465/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 0.1484 - accuracy: 0.9492\n",
      "Epoch 466/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.1474 - accuracy: 0.9492\n",
      "Epoch 467/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 0.1470 - accuracy: 0.9514\n",
      "Epoch 468/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.1467 - accuracy: 0.9470\n",
      "Epoch 469/500\n",
      "453/453 [==============================] - 0s 160us/sample - loss: 0.1459 - accuracy: 0.9536\n",
      "Epoch 470/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.1455 - accuracy: 0.9536\n",
      "Epoch 471/500\n",
      "453/453 [==============================] - 0s 160us/sample - loss: 0.1456 - accuracy: 0.9492\n",
      "Epoch 472/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.1445 - accuracy: 0.9470\n",
      "Epoch 473/500\n",
      "453/453 [==============================] - 0s 203us/sample - loss: 0.1446 - accuracy: 0.9492\n",
      "Epoch 474/500\n",
      "453/453 [==============================] - 0s 167us/sample - loss: 0.1461 - accuracy: 0.9514\n",
      "Epoch 475/500\n",
      "453/453 [==============================] - 0s 148us/sample - loss: 0.1454 - accuracy: 0.9514\n",
      "Epoch 476/500\n",
      "453/453 [==============================] - 0s 152us/sample - loss: 0.1478 - accuracy: 0.9514\n",
      "Epoch 477/500\n",
      "453/453 [==============================] - 0s 150us/sample - loss: 0.1449 - accuracy: 0.9470\n",
      "Epoch 478/500\n",
      "453/453 [==============================] - 0s 247us/sample - loss: 0.1430 - accuracy: 0.9448\n",
      "Epoch 479/500\n",
      "453/453 [==============================] - 0s 167us/sample - loss: 0.1424 - accuracy: 0.9514\n",
      "Epoch 480/500\n",
      "453/453 [==============================] - 0s 178us/sample - loss: 0.1419 - accuracy: 0.9470\n",
      "Epoch 481/500\n",
      "453/453 [==============================] - 0s 174us/sample - loss: 0.1423 - accuracy: 0.9514\n",
      "Epoch 482/500\n",
      "453/453 [==============================] - 0s 181us/sample - loss: 0.1423 - accuracy: 0.9470\n",
      "Epoch 483/500\n",
      "453/453 [==============================] - 0s 192us/sample - loss: 0.1420 - accuracy: 0.9514\n",
      "Epoch 484/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 0.1413 - accuracy: 0.9470\n",
      "Epoch 485/500\n",
      "453/453 [==============================] - 0s 207us/sample - loss: 0.1398 - accuracy: 0.9514\n",
      "Epoch 486/500\n",
      "453/453 [==============================] - 0s 176us/sample - loss: 0.1405 - accuracy: 0.9514\n",
      "Epoch 487/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 0.1389 - accuracy: 0.9536\n",
      "Epoch 488/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.1386 - accuracy: 0.9514\n",
      "Epoch 489/500\n",
      "453/453 [==============================] - 0s 171us/sample - loss: 0.1382 - accuracy: 0.9492\n",
      "Epoch 490/500\n",
      "453/453 [==============================] - 0s 168us/sample - loss: 0.1382 - accuracy: 0.9492\n",
      "Epoch 491/500\n",
      "453/453 [==============================] - 0s 172us/sample - loss: 0.1382 - accuracy: 0.9514\n",
      "Epoch 492/500\n",
      "453/453 [==============================] - 0s 167us/sample - loss: 0.1385 - accuracy: 0.9492\n",
      "Epoch 493/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.1366 - accuracy: 0.9492\n",
      "Epoch 494/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.1365 - accuracy: 0.9492\n",
      "Epoch 495/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.1366 - accuracy: 0.9514\n",
      "Epoch 496/500\n",
      "453/453 [==============================] - 0s 150us/sample - loss: 0.1355 - accuracy: 0.9536\n",
      "Epoch 497/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.1350 - accuracy: 0.9470\n",
      "Epoch 498/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.1350 - accuracy: 0.9470\n",
      "Epoch 499/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.1346 - accuracy: 0.9470\n",
      "Epoch 500/500\n",
      "453/453 [==============================] - 0s 145us/sample - loss: 0.1342 - accuracy: 0.9470\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(xs, ys, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3YXGelKThoTT"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "poeprYK8h-c7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'accuracy')\n",
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Vc6PHgxa6Hm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laurence went to dublin in minute minute minute both relations relations up entangled him up a jig jig lanigan glisten ructions him a hoops glisten glisten ructions were runctions able runctions ladies i nonsense ask glisten might ask glisten rat rat rat ladies ladies ladies twist him relations relations i invitation glisten glisten ructions him a mccarthy glisten ructions round mad at me a of man a near being ground suppose suppose suppose swore hall leg nolans much him a mchugh leg daughter jig suppose tea went him him were phelim hall table hall hall hall hall hall glisten glisten chaneys him a hoops\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Laurence went to dublin\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Course 3 - Week 4 - Lesson 1 - Notebook.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
